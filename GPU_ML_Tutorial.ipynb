{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.7"
    },
    "colab": {
      "name": "GPU ML Tutorial.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JYHaw/Machine-Learning-Cryptanalysis-of-a-Quantum-Random-Number-Generator/blob/master/GPU_ML_Tutorial.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mByrUohf1vKL",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "\n",
        "Step 1: Import packages. For faster computation, go to Runtime -> change runtime type and select \"GPU\".\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s8bflnIav9et",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\""
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qB_MRptwv9e9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YJVNzT_Uv9fF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.python.keras.layers import Input, Dense, Activation, Dropout, MaxPooling1D, Flatten, LSTM, Convolution1D\n",
        "from tensorflow.python.keras.models import Sequential\n",
        "from tensorflow.python.keras.optimizers import RMSprop\n",
        "from tensorflow.python.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "from tensorflow.python.keras.utils.data_utils import get_file\n",
        "from timeit import default_timer as timer \n",
        "import numpy as np\n",
        "import matplotlib.mlab as mlab\n",
        "import matplotlib.pyplot as plt\n",
        "import scipy.stats as scs\n",
        "import random\n",
        "import sys\n",
        "import os\n",
        "import glob"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VYcFJ3oY13un",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "\n",
        "Step 2: Generate pseudo-random numbers with a congruential random number generator.\n",
        "In this tutorial, we will use a short period of M=2^10, data length of 10000 (8000 for training, 2000 for testing) as demonstration\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P5tqKnSSsWAb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "ef3298f2-99ec-4a18-938d-6d8cb4798540"
      },
      "source": [
        "m_=10\n",
        "\n",
        "def rngint(nbit=8):\n",
        "    return int(rng()*(2**nbit))\n",
        "\n",
        "def rng(m=2**m_, a=1103515245, c=12345):\n",
        "    rng.current = (a*rng.current + c) % m\n",
        "    return float(rng.current)/m\n",
        "\n",
        "# setting the seed\n",
        "rng.current = 12\n",
        "\n",
        "data = np.array([rngint() for i in range(10000)])\n",
        "data.tofile('CRNG_10k.bin')\n",
        "print (data.shape)\n",
        "print (data[:10])"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(10000,)\n",
            "[ 85 218  22  62 116  13 205  41 131 112]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YSPyyjZk2-ic",
        "colab_type": "text"
      },
      "source": [
        "Step 3: Set the input parameters. Let us start with a step size of 20 for faster training\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BJNewFa7v9fL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#user-input variables\n",
        "\n",
        "alldata = []\n",
        "filenames = ['./CRNG_10k.bin']#Specify the directory + filename of the file to be trained and tested\n",
        "weightname ='CRNG_10k' #Specify the name to call this set of data\n",
        "\n",
        "# Length of input. Treating each input that consists of 100 \"words\" as a \"sentence\".\n",
        "maxlen = 100 #Default is 100\n",
        "# Distance between 2 consecutive \"sentences\"\n",
        "step = 20 #Default is 3, can be increased to speed up the training. The smaller the step, the higher the accurancy\n",
        "\n",
        "#Batch the data to relief hardware requirements. \n",
        "#Change this to smaller value if there is memory issue, or for validation. \n",
        "#The user can increase this (up to 1000000) if user's hardware permits. \n",
        "new_size = 1000"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zaIc62_2v9fP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 388
        },
        "outputId": "b906c80d-2bb9-4d0b-9286-6467056134ee"
      },
      "source": [
        "print('Data:'+weightname)\n",
        "\n",
        "for filename in filenames:\n",
        "    data = np.fromfile(filename, dtype='<i8')  \n",
        "    alldata.append(data[:10000])\n",
        "\n",
        "data=data[:8000]    \n",
        "mu, sigma = np.mean(data), np.std(data)\n",
        "#print('Mean='(mu),'Standard Deviation=' len(sigma))\n",
        "print('Mean=',mu)\n",
        "print('Standard Deviation=',sigma)\n",
        "\n",
        "# the histogram of the data\n",
        "n, bins, patches = plt.hist(data, list(range(np.min(data),np.max(data)+2)), density=1, facecolor='green', alpha=0.75)\n",
        "print('Max-probability',max(n))\n",
        "\n",
        "plt.xlabel('Bins')\n",
        "plt.ylabel('Probability')\n",
        "plt.title(r'$\\mathrm{Histogram\\ of \\ data:}\\ \\mu=%.2f,\\ \\sigma=%.2f$' % (mu,sigma))\n",
        "plt.grid(True)\n",
        "\n",
        "plt.show()\n",
        "\n",
        "del data  #delete data\n",
        "\n",
        "alldata = np.concatenate(alldata)    \n",
        "print(alldata.shape)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Data:CRNG_10k\n",
            "Mean= 127.658\n",
            "Standard Deviation= 73.82188724219938\n",
            "Max-probability 0.004\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": [
            "(10000,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KusPCIqVv9fW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "d0dab0af-3c42-45b4-b866-6396c62bd5c4"
      },
      "source": [
        "text = alldata[:8000]\n",
        "test1 = alldata[8000:9000]\n",
        "test2 = alldata[9000:10000]\n",
        "text = list(text)\n",
        "test1 = list(test1)\n",
        "test2 = list(test2)\n",
        "text = map(str,text)\n",
        "test1 = map(str,test1)\n",
        "test2 = map(str,test2)\n",
        "text_list = list(text)\n",
        "test1_list = list(test1)\n",
        "test2_list = list(test2)\n",
        "\n",
        "del text\n",
        "del test1\n",
        "del test2\n",
        "\n",
        "print(len(text_list), len(test1_list), len(test2_list))"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "8000 1000 1000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wnHLXjg_3ttk",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "\n",
        "Step 4: Preparing the data for ML\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5bS-2GE2v9fc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "outputId": "46760270-c6a5-44de-d806-33db77a99763"
      },
      "source": [
        "# Treating each number as a \"word\". Creating a dictionary.\n",
        "alldata = alldata.astype(np.str)\n",
        "chars = sorted(list(set(alldata)))\n",
        "\n",
        "print(chars)\n",
        "del alldata\n",
        "print('Total words:', len(chars))\n",
        "\n",
        "char_indices = dict((c, i) for i, c in enumerate(chars))\n",
        "indices_char = dict((i, c) for i, c in enumerate(chars))"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['0', '1', '10', '100', '101', '102', '103', '104', '105', '106', '107', '108', '109', '11', '110', '111', '112', '113', '114', '115', '116', '117', '118', '119', '12', '120', '121', '122', '123', '124', '125', '126', '127', '128', '129', '13', '130', '131', '132', '133', '134', '135', '136', '137', '138', '139', '14', '140', '141', '142', '143', '144', '145', '146', '147', '148', '149', '15', '150', '151', '152', '153', '154', '155', '156', '157', '158', '159', '16', '160', '161', '162', '163', '164', '165', '166', '167', '168', '169', '17', '170', '171', '172', '173', '174', '175', '176', '177', '178', '179', '18', '180', '181', '182', '183', '184', '185', '186', '187', '188', '189', '19', '190', '191', '192', '193', '194', '195', '196', '197', '198', '199', '2', '20', '200', '201', '202', '203', '204', '205', '206', '207', '208', '209', '21', '210', '211', '212', '213', '214', '215', '216', '217', '218', '219', '22', '220', '221', '222', '223', '224', '225', '226', '227', '228', '229', '23', '230', '231', '232', '233', '234', '235', '236', '237', '238', '239', '24', '240', '241', '242', '243', '244', '245', '246', '247', '248', '249', '25', '250', '251', '252', '253', '254', '255', '26', '27', '28', '29', '3', '30', '31', '32', '33', '34', '35', '36', '37', '38', '39', '4', '40', '41', '42', '43', '44', '45', '46', '47', '48', '49', '5', '50', '51', '52', '53', '54', '55', '56', '57', '58', '59', '6', '60', '61', '62', '63', '64', '65', '66', '67', '68', '69', '7', '70', '71', '72', '73', '74', '75', '76', '77', '78', '79', '8', '80', '81', '82', '83', '84', '85', '86', '87', '88', '89', '9', '90', '91', '92', '93', '94', '95', '96', '97', '98', '99']\n",
            "Total words: 256\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aS5dXkMkv9fh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "outputId": "d233247e-d30a-4f18-8abe-6e645b01549d"
      },
      "source": [
        "sentences = []\n",
        "next_chars = []\n",
        "for i in range(0, len(text_list) - maxlen, step):\n",
        "    sentences.append(text_list[i: (i + maxlen)])\n",
        "    next_chars.append(text_list[(i + maxlen)])\n",
        "print('nb sequences:', len(sentences))\n",
        "\n",
        "\n",
        "print('Start vectorization...')\n",
        "X = np.zeros((len(sentences), maxlen, len(chars)), dtype=np.bool)\n",
        "y = np.zeros((len(sentences), len(chars)), dtype=np.bool)\n",
        "for i, sentence in enumerate(sentences):\n",
        "    for t, char in enumerate(sentence):        \n",
        "        X[i, t, char_indices[char]] = 1\n",
        "    y[i, char_indices[next_chars[i]]] = 1\n",
        "print('Done vectorization!')"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "nb sequences: 395\n",
            "Start vectorization...\n",
            "Done vectorization!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E50Kvn3w3xoP",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "\n",
        "Step 5: Build model and train the data\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": false,
        "id": "rlPl1ojev9fk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 508
        },
        "outputId": "54a892ed-1633-4ba9-d000-9d53a32cf204"
      },
      "source": [
        "# build the RCNN model\n",
        "print('Build model...')\n",
        "model = Sequential()\n",
        "model.add(Convolution1D(filters=64, kernel_size=9, padding='same', activation='relu', input_shape=(maxlen, len(chars))))\n",
        "model.add(MaxPooling1D(pool_size=2))\n",
        "model.add(Convolution1D(filters=128, kernel_size=3, padding='same', activation='relu'))\n",
        "model.add(MaxPooling1D(pool_size=2))\n",
        "model.add(LSTM(128, return_sequences=False))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(len(chars)))\n",
        "model.add(Activation('softmax'))\n",
        "\n",
        "model.compile(loss='categorical_crossentropy', optimizer=tf.keras.optimizers.RMSprop(lr=0.0005), metrics=['accuracy'])\n",
        "print(model.summary())\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=4, verbose=1)\n",
        "weight ='weights_'+weightname+'.hdf5'\n",
        "print(weight)\n",
        "monitoring = ModelCheckpoint(weight, monitor='val_loss', verbose=1, save_best_only=True)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Build model...\n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv1d (Conv1D)              (None, 100, 64)           147520    \n",
            "_________________________________________________________________\n",
            "max_pooling1d (MaxPooling1D) (None, 50, 64)            0         \n",
            "_________________________________________________________________\n",
            "conv1d_1 (Conv1D)            (None, 50, 128)           24704     \n",
            "_________________________________________________________________\n",
            "max_pooling1d_1 (MaxPooling1 (None, 25, 128)           0         \n",
            "_________________________________________________________________\n",
            "lstm (LSTM)                  (None, 128)               131584    \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 256)               33024     \n",
            "_________________________________________________________________\n",
            "activation (Activation)      (None, 256)               0         \n",
            "=================================================================\n",
            "Total params: 336,832\n",
            "Trainable params: 336,832\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "weights_CRNG_10k.hdf5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": false,
        "id": "a4WM0kOCv9fo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "77052139-1dc8-43dc-ae6b-f68ca51d6643"
      },
      "source": [
        "model.fit(X, y, epochs=50, batch_size=128, validation_split=0.2, verbose=1, callbacks=[early_stopping,monitoring])\n",
        "model.load_weights(weight)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "3/3 [==============================] - ETA: 0s - loss: 5.5511 - accuracy: 0.0000e+00\n",
            "Epoch 00001: val_loss improved from inf to 5.53948, saving model to weights_CRNG_10k.hdf5\n",
            "3/3 [==============================] - 1s 499ms/step - loss: 5.5511 - accuracy: 0.0000e+00 - val_loss: 5.5395 - val_accuracy: 0.0253\n",
            "Epoch 2/50\n",
            "3/3 [==============================] - ETA: 0s - loss: 5.5345 - accuracy: 0.0285\n",
            "Epoch 00002: val_loss improved from 5.53948 to 5.53379, saving model to weights_CRNG_10k.hdf5\n",
            "3/3 [==============================] - 0s 155ms/step - loss: 5.5345 - accuracy: 0.0285 - val_loss: 5.5338 - val_accuracy: 0.0127\n",
            "Epoch 3/50\n",
            "3/3 [==============================] - ETA: 0s - loss: 5.5250 - accuracy: 0.0316\n",
            "Epoch 00003: val_loss improved from 5.53379 to 5.53101, saving model to weights_CRNG_10k.hdf5\n",
            "3/3 [==============================] - 0s 161ms/step - loss: 5.5250 - accuracy: 0.0316 - val_loss: 5.5310 - val_accuracy: 0.0000e+00\n",
            "Epoch 4/50\n",
            "3/3 [==============================] - ETA: 0s - loss: 5.5146 - accuracy: 0.0601\n",
            "Epoch 00004: val_loss improved from 5.53101 to 5.52793, saving model to weights_CRNG_10k.hdf5\n",
            "3/3 [==============================] - 0s 165ms/step - loss: 5.5146 - accuracy: 0.0601 - val_loss: 5.5279 - val_accuracy: 0.0000e+00\n",
            "Epoch 5/50\n",
            "3/3 [==============================] - ETA: 0s - loss: 5.5026 - accuracy: 0.0380\n",
            "Epoch 00005: val_loss improved from 5.52793 to 5.52482, saving model to weights_CRNG_10k.hdf5\n",
            "3/3 [==============================] - 1s 169ms/step - loss: 5.5026 - accuracy: 0.0380 - val_loss: 5.5248 - val_accuracy: 0.0000e+00\n",
            "Epoch 6/50\n",
            "3/3 [==============================] - ETA: 0s - loss: 5.4883 - accuracy: 0.0443\n",
            "Epoch 00006: val_loss improved from 5.52482 to 5.52281, saving model to weights_CRNG_10k.hdf5\n",
            "3/3 [==============================] - 1s 173ms/step - loss: 5.4883 - accuracy: 0.0443 - val_loss: 5.5228 - val_accuracy: 0.0000e+00\n",
            "Epoch 7/50\n",
            "3/3 [==============================] - ETA: 0s - loss: 5.4601 - accuracy: 0.0222\n",
            "Epoch 00007: val_loss improved from 5.52281 to 5.50308, saving model to weights_CRNG_10k.hdf5\n",
            "3/3 [==============================] - 1s 187ms/step - loss: 5.4601 - accuracy: 0.0222 - val_loss: 5.5031 - val_accuracy: 0.0000e+00\n",
            "Epoch 8/50\n",
            "3/3 [==============================] - ETA: 0s - loss: 5.4272 - accuracy: 0.0475\n",
            "Epoch 00008: val_loss improved from 5.50308 to 5.49544, saving model to weights_CRNG_10k.hdf5\n",
            "3/3 [==============================] - 0s 158ms/step - loss: 5.4272 - accuracy: 0.0475 - val_loss: 5.4954 - val_accuracy: 0.0000e+00\n",
            "Epoch 9/50\n",
            "3/3 [==============================] - ETA: 0s - loss: 5.3597 - accuracy: 0.0380\n",
            "Epoch 00009: val_loss improved from 5.49544 to 5.43520, saving model to weights_CRNG_10k.hdf5\n",
            "3/3 [==============================] - 0s 155ms/step - loss: 5.3597 - accuracy: 0.0380 - val_loss: 5.4352 - val_accuracy: 0.0000e+00\n",
            "Epoch 10/50\n",
            "3/3 [==============================] - ETA: 0s - loss: 5.3362 - accuracy: 0.0443\n",
            "Epoch 00010: val_loss improved from 5.43520 to 5.40978, saving model to weights_CRNG_10k.hdf5\n",
            "3/3 [==============================] - 0s 162ms/step - loss: 5.3362 - accuracy: 0.0443 - val_loss: 5.4098 - val_accuracy: 0.0000e+00\n",
            "Epoch 11/50\n",
            "3/3 [==============================] - ETA: 0s - loss: 5.2365 - accuracy: 0.0633\n",
            "Epoch 00011: val_loss did not improve from 5.40978\n",
            "3/3 [==============================] - 0s 161ms/step - loss: 5.2365 - accuracy: 0.0633 - val_loss: 5.4148 - val_accuracy: 0.0000e+00\n",
            "Epoch 12/50\n",
            "3/3 [==============================] - ETA: 0s - loss: 5.1709 - accuracy: 0.0475\n",
            "Epoch 00012: val_loss improved from 5.40978 to 5.35323, saving model to weights_CRNG_10k.hdf5\n",
            "3/3 [==============================] - 0s 162ms/step - loss: 5.1709 - accuracy: 0.0475 - val_loss: 5.3532 - val_accuracy: 0.0127\n",
            "Epoch 13/50\n",
            "3/3 [==============================] - ETA: 0s - loss: 5.1590 - accuracy: 0.0348\n",
            "Epoch 00013: val_loss improved from 5.35323 to 5.31581, saving model to weights_CRNG_10k.hdf5\n",
            "3/3 [==============================] - 1s 177ms/step - loss: 5.1590 - accuracy: 0.0348 - val_loss: 5.3158 - val_accuracy: 0.0000e+00\n",
            "Epoch 14/50\n",
            "3/3 [==============================] - ETA: 0s - loss: 5.0309 - accuracy: 0.0570\n",
            "Epoch 00014: val_loss improved from 5.31581 to 5.26368, saving model to weights_CRNG_10k.hdf5\n",
            "3/3 [==============================] - 1s 170ms/step - loss: 5.0309 - accuracy: 0.0570 - val_loss: 5.2637 - val_accuracy: 0.0000e+00\n",
            "Epoch 15/50\n",
            "3/3 [==============================] - ETA: 0s - loss: 4.9621 - accuracy: 0.0728\n",
            "Epoch 00015: val_loss improved from 5.26368 to 5.25831, saving model to weights_CRNG_10k.hdf5\n",
            "3/3 [==============================] - 0s 165ms/step - loss: 4.9621 - accuracy: 0.0728 - val_loss: 5.2583 - val_accuracy: 0.0000e+00\n",
            "Epoch 16/50\n",
            "3/3 [==============================] - ETA: 0s - loss: 4.9499 - accuracy: 0.0696\n",
            "Epoch 00016: val_loss improved from 5.25831 to 5.22196, saving model to weights_CRNG_10k.hdf5\n",
            "3/3 [==============================] - 1s 188ms/step - loss: 4.9499 - accuracy: 0.0696 - val_loss: 5.2220 - val_accuracy: 0.0000e+00\n",
            "Epoch 17/50\n",
            "3/3 [==============================] - ETA: 0s - loss: 4.8525 - accuracy: 0.0886\n",
            "Epoch 00017: val_loss improved from 5.22196 to 5.13318, saving model to weights_CRNG_10k.hdf5\n",
            "3/3 [==============================] - 0s 158ms/step - loss: 4.8525 - accuracy: 0.0886 - val_loss: 5.1332 - val_accuracy: 0.0000e+00\n",
            "Epoch 18/50\n",
            "3/3 [==============================] - ETA: 0s - loss: 4.8132 - accuracy: 0.0696\n",
            "Epoch 00018: val_loss improved from 5.13318 to 5.07230, saving model to weights_CRNG_10k.hdf5\n",
            "3/3 [==============================] - 1s 174ms/step - loss: 4.8132 - accuracy: 0.0696 - val_loss: 5.0723 - val_accuracy: 0.0000e+00\n",
            "Epoch 19/50\n",
            "3/3 [==============================] - ETA: 0s - loss: 4.7059 - accuracy: 0.0791\n",
            "Epoch 00019: val_loss improved from 5.07230 to 5.04139, saving model to weights_CRNG_10k.hdf5\n",
            "3/3 [==============================] - 0s 153ms/step - loss: 4.7059 - accuracy: 0.0791 - val_loss: 5.0414 - val_accuracy: 0.0000e+00\n",
            "Epoch 20/50\n",
            "3/3 [==============================] - ETA: 0s - loss: 4.6140 - accuracy: 0.1044\n",
            "Epoch 00020: val_loss improved from 5.04139 to 5.02081, saving model to weights_CRNG_10k.hdf5\n",
            "3/3 [==============================] - 0s 161ms/step - loss: 4.6140 - accuracy: 0.1044 - val_loss: 5.0208 - val_accuracy: 0.0000e+00\n",
            "Epoch 21/50\n",
            "3/3 [==============================] - ETA: 0s - loss: 4.6528 - accuracy: 0.1234\n",
            "Epoch 00021: val_loss improved from 5.02081 to 4.92905, saving model to weights_CRNG_10k.hdf5\n",
            "3/3 [==============================] - 0s 166ms/step - loss: 4.6528 - accuracy: 0.1234 - val_loss: 4.9290 - val_accuracy: 0.0000e+00\n",
            "Epoch 22/50\n",
            "3/3 [==============================] - ETA: 0s - loss: 4.5131 - accuracy: 0.1171\n",
            "Epoch 00022: val_loss improved from 4.92905 to 4.90831, saving model to weights_CRNG_10k.hdf5\n",
            "3/3 [==============================] - 1s 169ms/step - loss: 4.5131 - accuracy: 0.1171 - val_loss: 4.9083 - val_accuracy: 0.0000e+00\n",
            "Epoch 23/50\n",
            "3/3 [==============================] - ETA: 0s - loss: 4.5078 - accuracy: 0.1203\n",
            "Epoch 00023: val_loss improved from 4.90831 to 4.81486, saving model to weights_CRNG_10k.hdf5\n",
            "3/3 [==============================] - 1s 199ms/step - loss: 4.5078 - accuracy: 0.1203 - val_loss: 4.8149 - val_accuracy: 0.0000e+00\n",
            "Epoch 24/50\n",
            "3/3 [==============================] - ETA: 0s - loss: 4.3294 - accuracy: 0.1456\n",
            "Epoch 00024: val_loss improved from 4.81486 to 4.73539, saving model to weights_CRNG_10k.hdf5\n",
            "3/3 [==============================] - 0s 166ms/step - loss: 4.3294 - accuracy: 0.1456 - val_loss: 4.7354 - val_accuracy: 0.0000e+00\n",
            "Epoch 25/50\n",
            "3/3 [==============================] - ETA: 0s - loss: 4.3216 - accuracy: 0.1614\n",
            "Epoch 00025: val_loss improved from 4.73539 to 4.70461, saving model to weights_CRNG_10k.hdf5\n",
            "3/3 [==============================] - 1s 169ms/step - loss: 4.3216 - accuracy: 0.1614 - val_loss: 4.7046 - val_accuracy: 0.0000e+00\n",
            "Epoch 26/50\n",
            "3/3 [==============================] - ETA: 0s - loss: 4.2442 - accuracy: 0.1614\n",
            "Epoch 00026: val_loss did not improve from 4.70461\n",
            "3/3 [==============================] - 0s 145ms/step - loss: 4.2442 - accuracy: 0.1614 - val_loss: 4.7476 - val_accuracy: 0.0000e+00\n",
            "Epoch 27/50\n",
            "3/3 [==============================] - ETA: 0s - loss: 4.2345 - accuracy: 0.1487\n",
            "Epoch 00027: val_loss improved from 4.70461 to 4.56472, saving model to weights_CRNG_10k.hdf5\n",
            "3/3 [==============================] - 0s 166ms/step - loss: 4.2345 - accuracy: 0.1487 - val_loss: 4.5647 - val_accuracy: 0.0000e+00\n",
            "Epoch 28/50\n",
            "3/3 [==============================] - ETA: 0s - loss: 4.0863 - accuracy: 0.1772\n",
            "Epoch 00028: val_loss improved from 4.56472 to 4.53439, saving model to weights_CRNG_10k.hdf5\n",
            "3/3 [==============================] - 1s 172ms/step - loss: 4.0863 - accuracy: 0.1772 - val_loss: 4.5344 - val_accuracy: 0.0000e+00\n",
            "Epoch 29/50\n",
            "3/3 [==============================] - ETA: 0s - loss: 4.0547 - accuracy: 0.1804\n",
            "Epoch 00029: val_loss improved from 4.53439 to 4.49084, saving model to weights_CRNG_10k.hdf5\n",
            "3/3 [==============================] - 1s 167ms/step - loss: 4.0547 - accuracy: 0.1804 - val_loss: 4.4908 - val_accuracy: 0.0000e+00\n",
            "Epoch 30/50\n",
            "3/3 [==============================] - ETA: 0s - loss: 4.0855 - accuracy: 0.1772\n",
            "Epoch 00030: val_loss improved from 4.49084 to 4.41215, saving model to weights_CRNG_10k.hdf5\n",
            "3/3 [==============================] - 0s 166ms/step - loss: 4.0855 - accuracy: 0.1772 - val_loss: 4.4122 - val_accuracy: 0.0000e+00\n",
            "Epoch 31/50\n",
            "3/3 [==============================] - ETA: 0s - loss: 3.9332 - accuracy: 0.2184\n",
            "Epoch 00031: val_loss improved from 4.41215 to 4.39756, saving model to weights_CRNG_10k.hdf5\n",
            "3/3 [==============================] - 1s 184ms/step - loss: 3.9332 - accuracy: 0.2184 - val_loss: 4.3976 - val_accuracy: 0.0000e+00\n",
            "Epoch 32/50\n",
            "3/3 [==============================] - ETA: 0s - loss: 3.8450 - accuracy: 0.2152\n",
            "Epoch 00032: val_loss improved from 4.39756 to 4.29867, saving model to weights_CRNG_10k.hdf5\n",
            "3/3 [==============================] - 0s 156ms/step - loss: 3.8450 - accuracy: 0.2152 - val_loss: 4.2987 - val_accuracy: 0.0000e+00\n",
            "Epoch 33/50\n",
            "3/3 [==============================] - ETA: 0s - loss: 3.8028 - accuracy: 0.2089\n",
            "Epoch 00033: val_loss did not improve from 4.29867\n",
            "3/3 [==============================] - 0s 158ms/step - loss: 3.8028 - accuracy: 0.2089 - val_loss: 4.3065 - val_accuracy: 0.0000e+00\n",
            "Epoch 34/50\n",
            "3/3 [==============================] - ETA: 0s - loss: 3.7354 - accuracy: 0.2152\n",
            "Epoch 00034: val_loss improved from 4.29867 to 4.29676, saving model to weights_CRNG_10k.hdf5\n",
            "3/3 [==============================] - 1s 170ms/step - loss: 3.7354 - accuracy: 0.2152 - val_loss: 4.2968 - val_accuracy: 0.0127\n",
            "Epoch 35/50\n",
            "3/3 [==============================] - ETA: 0s - loss: 3.7567 - accuracy: 0.2468\n",
            "Epoch 00035: val_loss improved from 4.29676 to 4.15658, saving model to weights_CRNG_10k.hdf5\n",
            "3/3 [==============================] - 0s 156ms/step - loss: 3.7567 - accuracy: 0.2468 - val_loss: 4.1566 - val_accuracy: 0.0000e+00\n",
            "Epoch 36/50\n",
            "3/3 [==============================] - ETA: 0s - loss: 3.6205 - accuracy: 0.2722\n",
            "Epoch 00036: val_loss improved from 4.15658 to 4.06516, saving model to weights_CRNG_10k.hdf5\n",
            "3/3 [==============================] - 0s 163ms/step - loss: 3.6205 - accuracy: 0.2722 - val_loss: 4.0652 - val_accuracy: 0.0000e+00\n",
            "Epoch 37/50\n",
            "3/3 [==============================] - ETA: 0s - loss: 3.5678 - accuracy: 0.2722\n",
            "Epoch 00037: val_loss did not improve from 4.06516\n",
            "3/3 [==============================] - 0s 160ms/step - loss: 3.5678 - accuracy: 0.2722 - val_loss: 4.0939 - val_accuracy: 0.0000e+00\n",
            "Epoch 38/50\n",
            "3/3 [==============================] - ETA: 0s - loss: 3.6279 - accuracy: 0.2310\n",
            "Epoch 00038: val_loss did not improve from 4.06516\n",
            "3/3 [==============================] - 0s 149ms/step - loss: 3.6279 - accuracy: 0.2310 - val_loss: 4.1172 - val_accuracy: 0.0000e+00\n",
            "Epoch 39/50\n",
            "3/3 [==============================] - ETA: 0s - loss: 3.6148 - accuracy: 0.2247\n",
            "Epoch 00039: val_loss improved from 4.06516 to 4.01221, saving model to weights_CRNG_10k.hdf5\n",
            "3/3 [==============================] - 1s 183ms/step - loss: 3.6148 - accuracy: 0.2247 - val_loss: 4.0122 - val_accuracy: 0.0000e+00\n",
            "Epoch 40/50\n",
            "3/3 [==============================] - ETA: 0s - loss: 3.4681 - accuracy: 0.2722\n",
            "Epoch 00040: val_loss improved from 4.01221 to 3.91670, saving model to weights_CRNG_10k.hdf5\n",
            "3/3 [==============================] - 0s 163ms/step - loss: 3.4681 - accuracy: 0.2722 - val_loss: 3.9167 - val_accuracy: 0.0000e+00\n",
            "Epoch 41/50\n",
            "3/3 [==============================] - ETA: 0s - loss: 3.4459 - accuracy: 0.2690\n",
            "Epoch 00041: val_loss improved from 3.91670 to 3.90315, saving model to weights_CRNG_10k.hdf5\n",
            "3/3 [==============================] - 0s 167ms/step - loss: 3.4459 - accuracy: 0.2690 - val_loss: 3.9032 - val_accuracy: 0.0000e+00\n",
            "Epoch 42/50\n",
            "3/3 [==============================] - ETA: 0s - loss: 3.3488 - accuracy: 0.2753\n",
            "Epoch 00042: val_loss improved from 3.90315 to 3.80190, saving model to weights_CRNG_10k.hdf5\n",
            "3/3 [==============================] - 0s 165ms/step - loss: 3.3488 - accuracy: 0.2753 - val_loss: 3.8019 - val_accuracy: 0.0000e+00\n",
            "Epoch 43/50\n",
            "3/3 [==============================] - ETA: 0s - loss: 3.2520 - accuracy: 0.3006\n",
            "Epoch 00043: val_loss improved from 3.80190 to 3.73811, saving model to weights_CRNG_10k.hdf5\n",
            "3/3 [==============================] - 0s 158ms/step - loss: 3.2520 - accuracy: 0.3006 - val_loss: 3.7381 - val_accuracy: 0.0000e+00\n",
            "Epoch 44/50\n",
            "3/3 [==============================] - ETA: 0s - loss: 3.2815 - accuracy: 0.3006\n",
            "Epoch 00044: val_loss did not improve from 3.73811\n",
            "3/3 [==============================] - 0s 165ms/step - loss: 3.2815 - accuracy: 0.3006 - val_loss: 3.7598 - val_accuracy: 0.0000e+00\n",
            "Epoch 45/50\n",
            "3/3 [==============================] - ETA: 0s - loss: 3.2916 - accuracy: 0.2690\n",
            "Epoch 00045: val_loss did not improve from 3.73811\n",
            "3/3 [==============================] - 0s 158ms/step - loss: 3.2916 - accuracy: 0.2690 - val_loss: 3.7939 - val_accuracy: 0.0000e+00\n",
            "Epoch 46/50\n",
            "3/3 [==============================] - ETA: 0s - loss: 3.2189 - accuracy: 0.2848\n",
            "Epoch 00046: val_loss improved from 3.73811 to 3.72136, saving model to weights_CRNG_10k.hdf5\n",
            "3/3 [==============================] - 1s 173ms/step - loss: 3.2189 - accuracy: 0.2848 - val_loss: 3.7214 - val_accuracy: 0.0127\n",
            "Epoch 47/50\n",
            "3/3 [==============================] - ETA: 0s - loss: 3.2075 - accuracy: 0.2943\n",
            "Epoch 00047: val_loss did not improve from 3.72136\n",
            "3/3 [==============================] - 0s 161ms/step - loss: 3.2075 - accuracy: 0.2943 - val_loss: 3.7343 - val_accuracy: 0.0000e+00\n",
            "Epoch 48/50\n",
            "3/3 [==============================] - ETA: 0s - loss: 3.1014 - accuracy: 0.3070\n",
            "Epoch 00048: val_loss improved from 3.72136 to 3.57061, saving model to weights_CRNG_10k.hdf5\n",
            "3/3 [==============================] - 0s 162ms/step - loss: 3.1014 - accuracy: 0.3070 - val_loss: 3.5706 - val_accuracy: 0.0000e+00\n",
            "Epoch 49/50\n",
            "3/3 [==============================] - ETA: 0s - loss: 3.0218 - accuracy: 0.3133\n",
            "Epoch 00049: val_loss did not improve from 3.57061\n",
            "3/3 [==============================] - 1s 177ms/step - loss: 3.0218 - accuracy: 0.3133 - val_loss: 3.6096 - val_accuracy: 0.0000e+00\n",
            "Epoch 50/50\n",
            "3/3 [==============================] - ETA: 0s - loss: 3.0423 - accuracy: 0.2975\n",
            "Epoch 00050: val_loss improved from 3.57061 to 3.51205, saving model to weights_CRNG_10k.hdf5\n",
            "3/3 [==============================] - 0s 161ms/step - loss: 3.0423 - accuracy: 0.2975 - val_loss: 3.5121 - val_accuracy: 0.0000e+00\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zdqg2iCI32nQ",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "\n",
        "Step 6: Perform the test for ML\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kxApurjmv9ft",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 181
        },
        "outputId": "dc567e2d-f14b-45d9-a7c1-c9e00fbbcb4a"
      },
      "source": [
        "tests = [test1_list,test2_list]\n",
        "del test1_list\n",
        "del test2_list\n",
        "average = 0\n",
        "start = timer()\n",
        "for test in tests:\n",
        "    n_batch = int(len(test)/new_size)\n",
        "    for ib in range(n_batch):\n",
        "        test_ = test[ib*new_size:(ib+1)*new_size]\n",
        "    \n",
        "        maxlen = 100\n",
        "        step = 1\n",
        "        sentences = []\n",
        "        next_chars = []\n",
        "        for i in range(0, len(test_) - maxlen, step):\n",
        "            sentences.append(test_[i: (i + maxlen)])\n",
        "            next_chars.append(test_[(i + maxlen)])\n",
        "        print('nb sequences:', len(sentences))\n",
        "\n",
        "        print('Vectorization...')\n",
        "        Xt = np.zeros((len(sentences), maxlen, len(chars)), dtype=np.bool)\n",
        "        yt = np.zeros((len(sentences), len(chars)), dtype=np.bool)\n",
        "        for i, sentence in enumerate(sentences):\n",
        "\n",
        "            for t, char in enumerate(sentence):        \n",
        "                Xt[i, t, char_indices[char]] = 1       \n",
        "            yt[i, char_indices[next_chars[i]]] = 1\n",
        "        n_true = 0\n",
        "        diversity = 1\n",
        "        for i,x in enumerate(Xt):\n",
        "            if i % 100000 == 0:\n",
        "                print (\"Processed %d %d\" % (i,n_true))\n",
        "            x = x.reshape(1,maxlen,-1)\n",
        "            preds = model.predict(x, verbose=0)[0]\n",
        "            next_index = np.argmax(preds)      \n",
        "            next_char = indices_char[next_index]\n",
        "            if next_char == indices_char[np.argmax(yt[i])]:\n",
        "                n_true += 1\n",
        "        print (\"%d_%d_%.5f\" % (n_true,yt.shape[0],(float(n_true)/yt.shape[0])))\n",
        "        average = average + (float(n_true)/yt.shape[0])\n",
        "print(\"Time taken: %.5f hours, P_ML = %.5f, P_8bit= %.5f\" % (float(timer()-start)/3600, average/(2*n_batch),1/2**8))"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "nb sequences: 900\n",
            "Vectorization...\n",
            "Processed 0 0\n",
            "50_900_0.05556\n",
            "nb sequences: 900\n",
            "Vectorization...\n",
            "Processed 0 0\n",
            "50_900_0.05556\n",
            "Time taken: 0.02477 hours, P_ML = 0.05556, P_8bit= 0.00391\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7CWhWU1P35J0",
        "colab_type": "text"
      },
      "source": [
        "We see that the machine learning guessing can outperform the expected probability of 1/2^8 (~0.0039) for an 8-bit distribution. \n",
        "Now re-run the whole code again with step size of 3, and observe the outcome.\n",
        "\n",
        "Once you have completed this, you are welcome to check out the full version of our codes on the github: https://github.com/NeuroSyd/Machine-Learning-Cryptanalysis-of-a-Quantum-Random-Number-Generator\n",
        "\n",
        "In particular, under the \"Benchmark\" folder, you can evaluate your binary data, where the first 80,000,000 bit will be trained and tested in 8-bit format.\n",
        "Of course, unlike the tutorial here will smaller size and lesser test sets, the whole test will take much longer time, depending on the specification of your hardware."
      ]
    }
  ]
}